First step for running a topic model with ToPan was to have a .tsv file. ToPan supports a number of different formats for data entry, but honestly, a tab-separated file was the only one we felt comfortable with.

The tab-separated file consists of two columns. The first has the urn of a particular scholion, while the second has a lemmatized version of that scholion.

The settings for data entry are fairly straightforward. There is no header, it is, again, a tab-separated file, and there are no quotes. Having submitted this, the text appeared as it was expected on the right part of the ToPan interface.

We skipped over the morphology service since we were working with an already lemmatized version of the text.

For the stop words, we had to do considerable work here. Although the text was lemmatized, due to the nature of our dataset, not every word could be properly lemmatized. Additionally, some Greek words can be validly parsed in mulitple ways, all of which are represented in our lemmatized edition. As a result, our dataset is fairly messy.

According to Thomas Koentges, the standard procedure for creating a stop-word list is to take out some number of the most frequently occurring words. The idea behind this is that the most common words (e.g. in English: the, a, and, etc.) are not useful for identifying topics. We used our own word frequency script to find the most common words in the scholia. While ToPan has a feature that can do this for you, using it is slightly tedious. After looking at the results of our frequency script, we decided to cap our stop-word list at the most frequently occurring 251 words. We chose this number because after this point, the words generally seemed to be significant for topic modelling. A significant word is one which is more than a function word; thus, significant words are typically verbs and nouns. 

The next step, assuming every one of the 251 most common words was insignificant for topic modelling, would be to enter this data into ToPan, which lets you define how many of the most common words in a corpus should be excluded. However, there were some significant words contained in the 251 most common. Again, ToPan includes a feature which lets you record which words within your defined stop-word list should actually be excluded and therefore be part of the topic modelling analysis. But, the feature is still rather cumbersome to use within ToPan. As a result, we simply looked at our own list of most frequently occurring words from before, and recorded the significant words in a separate text file.

As stated before, however, this data was very messy. The task of recording which words were significant was NOT as simple as asking if the word was significant or not. Because a particular form of a Greek word, if taken out of context, could ostensibly be from a number of different words, our lemmatized text contained more words than actually appear in the manuscript. Sometimes these extra words are harmless, such as a form of τις always being parsed as τις and τίς since both τις and τίς are insignificant for topic modelling and appear frequently enough to be caught in our requirements for stop-words. Other times the extra words were not so innocuous. For example, the 74th most common word in the corpus of Greek scholia is apparently πηρός, an adjective referring to lameness in a leg. While it is possible that πηρός appears occasionally in the scholia as perhaps a word conatined in a quote from the *Iliad*, it is highly doubtful that it should be so common that it appears more than the preposition ὑπό. What appears to have happened is that the actually common preposition παρά can also be parsed as the Doric feminine singular nominative, as well as the Doric neuter plural nominative and accusative forms of πηρός. Thus πηρός, although a word that is not a function word, has to be excluded from analysis since it does not actually belong in the scholia. 

Similarly, a word might be parsed in two ways but have essentially equivalent lemmata. For example the 73rd most common word in the scholia was χράω, while the 235th most common word was χράομαι. We decided that because these words were essentially the same, it was only necessary to include one in the analysis. For this instance, and others like it, we chose the more frequently occurring word as the one to include for topic modelling. 

Finally, there was the matter of abbreviations and expansions. The name Aristarchus appeared multiple times within the list, as Ἀρίσταρχος (31st most common), ἀρίσταρχος (32nd most common), and Ἀρισταρχ (164th most common), to name a few. In a similar fashion to how we dealt with the previous case of words that had essentially equivalent lemmata, we chose to include the most frequently occurring expansion.

The final confounding factor of these stop-word lists, and the data in general, is the presence of Byzantine orthographic variants. At this stage in the project, we have no way of aligning the Byzantine orthographic variants with their normalized counterparts. Again, this can be harmless. δέ is the 7th most common word in the scholia, while δε is the 46th most common word. Although δε is undoubtedly the same word as δέ, the computer has no way of knowing this since the literal strings are not the same. In this case, however, both are function words and very common so both are excluded from analysis. This becomes an issue in instances where words do not appear frequently enough to appear in the 251 most common words, but common enough to make an impact on topic modelling. There is a collection of Byzantine orthographic variants and their normalized counterparts as part of the Homer Multitext project 
